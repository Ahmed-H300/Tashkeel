{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "nQVagDa_aNAP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2nSoT6rEeEpo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "da9c410c-e76d-4ee9-ac1f-f53193d640ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import os\n",
        "# # Check if the folder exists, and create it if it doesn't\n",
        "# folder_path = os.path.join('/content/drive/MyDrive/', 'Tashkeel')\n",
        "# if not os.path.exists(folder_path):\n",
        "#     print(\"Creating Tashkeel in your drive ........\")\n",
        "#     os.makedirs(folder_path)\n",
        "# else: print(\"Tashkeel Already Exists in your drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %run cleaning.py --mode train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "A4mtvdbygFVp",
        "outputId": "aed8c105-17cd-4ee6-cbf5-eee18ba12336"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Cleaning .....\n",
            "Done Cleaning :D\n",
            "Tokenization to Sentences [\n",
            ".،؛:]+ .....\n",
            "Done Tokenizing :D\n",
            "Fxing Diacritization issues .......\n",
            "Done Fxing Diacritization issues :D\n",
            "Removing Tashkel ......\n",
            "Removing Tashkel Done :D 140132 Sentences\n",
            "Getting Tashkel ......\n",
            "Getting Tashkeel Done :D 140132 Sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %run cleaning.py --mode validate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1qvwf3BE_68S",
        "outputId": "750ada23-e45b-49e0-ec22-426daeb867b7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation mode selected.\n",
            "Cleaning .....\n",
            "Done Cleaning :D\n",
            "Tokenization to Sentences [\n",
            ".،؛:]+ .....\n",
            "Done Tokenizing :D\n",
            "Fxing Diacritization issues .......\n",
            "Done Fxing Diacritization issues :D\n",
            "Removing Tashkel ......\n",
            "Removing Tashkel Done :D 7102 Sentences\n",
            "Getting Tashkel ......\n",
            "Getting Tashkeel Done :D 7102 Sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import get_params\n",
        "from Globals import vocab_map,classes\n",
        "\n",
        "t_sentences, t_labels, t_size = get_params(vocab_map, classes, '/content/drive/MyDrive/Tashkeel/train_X.pickle', '/content/drive/MyDrive/Tashkeel/train_Y.pickle')\n",
        "v_sentences, v_labels, v_size = get_params(vocab_map, classes, '/content/drive/MyDrive/Tashkeel/val_X.pickle', '/content/drive/MyDrive/Tashkeel/val_Y.pickle')\n",
        "# test_sentences, test_labels, test_size = get_params(vocab, tag_map, '/content/drive/MyDrive/data/large/test/sentences.txt', '/content/drive/MyDrive/data/large/test/labels.txt')\n",
        "\n",
        "from tashkeel_data_set import TashkeelDataset\n",
        "max_length=50\n",
        "train_dataset = TashkeelDataset(t_sentences, t_labels, vocab_map['<PAD>'],max_length)\n",
        "val_dataset = TashkeelDataset(v_sentences, v_labels, vocab_map['<PAD>'],max_length)\n",
        "# test_dataset = TashkeelDataset(test_sentences, test_labels, vocab_map['<PAD>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yY3_pgqVt-j2",
        "outputId": "3fe479fd-869e-4fbb-c042-7d8f77c3dcd5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ا': 0, 'ض': 1, 'م': 2, 'ظ': 3, 'ف': 4, 'إ': 5, 'ؤ': 6, 'ة': 7, 'ذ': 8, 'آ': 9, 'ق': 10, 'س': 11, 'ع': 12, 'د': 13, 'ز': 14, 'ص': 15, 'أ': 16, 'ن': 17, 'ت': 18, 'ب': 19, 'ى': 20, 'ه': 21, 'ر': 22, 'ش': 23, 'خ': 24, 'ث': 25, 'ط': 26, 'ج': 27, 'ح': 28, 'ئ': 29, 'ي': 30, 'ك': 31, 'ل': 32, 'ء': 33, 'و': 34, 'غ': 35, '<s>': 36, '</s>': 37, ' ': 38, '<PAD>': 39, '<UNK>': 40}\n",
            "{'َ': 0, 'ً': 1, 'ُ': 2, 'ٌ': 3, 'ِ': 4, 'ٍ': 5, 'ْ': 6, 'ّ': 7, 'َّ': 8, 'ًّ': 9, 'ُّ': 10, 'ٌّ': 11, 'ِّ': 12, 'ٍّ': 13, '': 14}\n",
            "Padding ..... with  50 : 7102 7102\n",
            "Done Padding ..... 14319 14319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tashkeel_nn import Tashkeel\n",
        "model = Tashkeel()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Bh0Ap0-LQBC_",
        "outputId": "0acfbbc3-b968-441e-dd51-24d85c713132"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tashkeel(\n",
            "  (embedding): Embedding(41, 50)\n",
            "  (lstm): LSTM(50, 50, batch_first=True)\n",
            "  (linear): Linear(in_features=50, out_features=15, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tashkeel_train import train\n",
        "train(model, train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SuMhZPYA8dBI",
        "outputId": "ae002ff4-405f-43d3-dfbb-757b85eef0a1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 552/552 [02:36<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss: 0.0008696750737726688         | Train Accuracy: 0.8368943417604986\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 552/552 [02:27<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss: 0.00074869638774544         | Train Accuracy: 0.8591430493591106\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 552/552 [02:40<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss: 0.0007269073976203799         | Train Accuracy: 0.8629596345867856\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 552/552 [02:51<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss: 0.0007165319984778762         | Train Accuracy: 0.8648658027051909\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 552/552 [02:38<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss: 0.0007100930088199675         | Train Accuracy: 0.8659922809999292\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model using pickle\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/Tashkeel/model.pickle', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Read the model using pickle\n",
        "# import pickle\n",
        "# # Load the model using pickle\n",
        "# with open('model.pkl', 'rb') as f:\n",
        "#     loaded_model = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "sztsj_c3_tex"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "from tashkeel_evaluate import evaluate\n",
        "evaluate(model, val_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsgAntunBqYk",
        "outputId": "59038a6d-b016-4d6c-bbaa-71617815704c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28/28 [00:03<00:00,  8.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.8657881136950905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}